<!DOCTYPE html><!--Author: Pranav Rajpurkar 2016--><html><head><meta charset="utf-8"><title>A Conversational Question Answering Challenge</title><meta name="description" content="CoQA is a large-scale dataset for building Conversational Question Answering systems."><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta property="og:image" content="/logo.png"><link rel="image_src" type="image/png" href="/coqa/logo.png"><link rel="shortcut icon" href="/coqa/favicon.ico" type="image/x-icon"><link rel="icon" href="/coqa/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="/coqa/bower_components/bootstrap/dist/css/bootstrap.min.css"><link rel="stylesheet" href="/coqa/stylesheets/layout.css"><link rel="stylesheet" href="/coqa/stylesheets/index.css"><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/coqa/javascripts/analytics.js"></script></head><body><div class="navbar navbar-default navbar-fixed-top" id="topNavbar" role="navigation"><div class="container clearfix" id="navContainer"><div class="rightNav"><div class="collapseDiv"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><span class="glyphicon glyphicon-menu-hamburger"></span></button></div><div class="collapse navbar-collapse" id="navbar"><ul class="nav navbar-nav navbar-right"><li><a href="/coqa/">Home</a></li></ul></div></div><div class="leftNav"><div class="brandDiv"><a class="navbar-brand" href="/coqa/">CoQA</a></div></div></div></div><div class="cover" id="topCover"><div class="container"><div class="row"><div class="col-md-12"><h1 id="appTitle"><img src="logo.png" width="10%"> CoQA <img src="logo.png" width="10%" style="visibility:hidden"></h1><h2 id="appSubtitle">A Conversational Question Answering Challenge</h2></div></div></div></div><div class="cover" id="contentCover"><div class="container"><div class="row"><div class="col-md-5"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>What is CoQA?</h2></div><p> CoQA is a large-scale dataset for building <span><b>Co</b>nversational <b>Q</b>uestion <b>A</b>nswering </span>systems. The CoQA challenge is to build sytems that has to understand a text passage and answer a series of interconnected questions that appear in a conversation. </p><hr><p>Each conversation in <b> CoQA </b>is collected by pairing two crowdworkers to chat about a passage in the form of questions and answers. 
CoQA contains 127,000+ questions with answers collected from 8000+ conversations. 
The unique features of CoQA include 1) the questions are conversational; 2) the answers can be free-form text; 3) each answer also contains an evidence highlighted in the passage; and 4) the passages are collected from seven diverse domains.
CoQA has challenging phenomena not present in existing reading comprehension datasets, e.g., coreference and pragmatic reasoning.</p><a class="btn actionBtn" href="http://arxiv.org/abs/TODO">CoQA paper (Reddy et al. '18)</a><div class="infoHeadline"><h2>Download</h2></div><p>To browse conversations in CoQA, click below.<ul class="list-unstyled"><li><a class="btn actionBtn inverseBtn" href="/coqa/dataset/train-v2.0.json" download>Browse Dev Set</a></li></ul></p><p> To download the dataset in json format, click below (distributed under the  <a href="http://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA 4.0</a> license):<ul class="list-unstyled"><li><a class="btn actionBtn inverseBtn" href="/coqa/dataset/train-v2.0.json" download>Download Training Set (40 MB)</a></li><li><a class="btn actionBtn inverseBtn" href="/coqa/dataset/dev-v2.0.json" download>Download Dev Set v2.0 (4 MB)</a></li></ul></p><p>To evaluate your models, we have also made available the evaluation script we will use for official evaluation, along with a sample prediction file that the script will take as input. To run the evaluation, use <code>python evaluate-v2.0.py &lt;path_to_dev-v2.0&gt; &lt;path_to_predictions&gt;</code>.<ul class="list-unstyled"><li><a class="btn actionBtn inverseBtn" href="https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/" download>Evaluation Script</a></li><li><a class="btn actionBtn inverseBtn" href="https://worksheets.codalab.org/bundles/0x8731effab84f41b7b874a070e40f61e2/" download>Sample Prediction File (on Dev Set)</a></li></ul></p><p>Once you have a built a model that works to your expectations on the dev set, you submit it to get official scores on the dev and a hidden test set. To preserve the integrity of test results, we do not release the test set to the public. Instead, we require you to submit your model so that we can run it on the test set for you. Here's a tutorial walking you through official evaluation of your model:</p><a class="btn actionBtn inverseBtn" href="https://worksheets.codalab.org/worksheets/0x8212d84ca41c4150b555a075b19ccc05/">Submission Tutorial</a><div class="infoHeadline"><h2>Have Questions?</h2></div><p> If you have a question about the challenge, please post as an issue on our <a href="https://github.com/stanfordnlp/coqa">github page.</a>.</p></div><div class="infoSubheadline"><a href="https://twitter.com/share" class="twitter-share-button" data-url="https://stanford-qa.com" data-text="A Conversational Question Answering Challenge  - 120,000+ questions from 8000+ conversations on text passages" data-via="stanfordnlp" data-size="large" data-hashtags="CoQA">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script><!-- Place this tag where you want the button to render. -->
<a class="github-button" href="https://github.com/stanfordnlp/coqa" data-icon="octicon-star" data-style="mega" data-count-href="/stanfordnlp/coqa/stargazers" data-count-api="/repos/stanfordnlp/coqa#stargazers_count" data-count-aria-label="# stargazers on GitHub" aria-label="Star stanfordnlp/coqa on GitHub">Star</a></div></div></div><div class="col-md-7"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>Leaderboard</h2></div><table class="table performanceTable"><tr><th>Rank</th><th>Model</th><th>In-domain</th><th>Out-of-domain</th><th>Overall</th></tr><tr class="human-row"><td></td><td>Human Performance<p class="institution">Stanford University</p><a href="http://arxiv.org/abs/1606.05250">(Reddy et al. '18)</a></td><td>89.387</td><td>87.374</td><td>88.798</td></tr><tr><td> <p>1</p><span class="date label label-default">Aug 01, 2018</span></td><td style="word-break:break-word;">DrQA + Seq2seq with copy attention (single model)<p class="institution">Stanford University</p></td><td><b>67.029</b></td><td><b>60.366</b></td><td><b>65.081</b></td></tr></table></div></div></div></div></div></div><nav class="navbar navbar-default navbar-static-bottom footer"><div class="container clearfix"><div class="rightNav"><div><ul class="nav navbar-nav navbar-right"><li><a href="/coqa/">CoQA</a></li><li><a href="http://nlp.stanford.edu">Stanford NLP Group</a></li></ul></div></div></div></nav><script src="/coqa/bower_components/jquery/dist/jquery.min.js"></script><script src="/coqa/bower_components/bootstrap/dist/js/bootstrap.min.js"></script></body></html>